{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics - Protein subcellular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "from  sklearn import preprocessing\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingRegressor,VotingClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression,RandomizedLogisticRegression, Lasso\n",
    "from sklearn.metrics import f1_score,confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,ShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load data and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9222\n",
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "def preprocess_pipeline(*files):\n",
    "    #p = re.compile(\"(\\w+\\|\\w+)\\|(\\w+\\s[0-9a-zA-Z_\\s\\(\\)\\-\\/,\\.\\>\\:\\'\\[\\]\\+]+)OS=([0-9a-zA-Z_\\s\\(\\)\\-\\/,\\.\\>\\:\\']+)GN=([0-9a-zA-Z_\\s\\(\\)\\-\\/,\\.\\>\\:\\']+)PE=([0-9])+\\s[SV=]+([0-9])|(\\w+\\|\\w+)\\|(\\w+\\s[0-9a-zA-Z_\\s\\(\\)\\-\\/,\\.\\>\\:\\'\\[\\]]+)OS=([0-9a-zA-Z_\\s\\(\\)\\-\\/,\\.\\>\\:\\']+)PE=([0-9])+\\s[SV=]+([0-9])\")\n",
    "    p=re.compile(\"\\|\\w+\\s(.+)OS=([0-9a-zA-Z_\\s\\(\\)\\-\\/,\\.\\>\\:\\']+)(?:\\sGN|\\sPE)\")\n",
    "    data_features = []\n",
    "    data_labels = []\n",
    "    sequence = ''\n",
    "    list_meta=[]\n",
    "    for file in files:\n",
    "        label = os.path.splitext(file)[0]\n",
    "        f = open(file, \"r\")\n",
    "        dict_meta = defaultdict(float)\n",
    "        first_line = f.readline()\n",
    "        meta_info = p.search(first_line)\n",
    "        try:\n",
    "            dict_meta[\"organism\"] = meta_info.group(2)\n",
    "            dict_meta[\"protein\"] = meta_info.group(1)\n",
    "            dict_meta[\"class\"] = label\n",
    "        except:\n",
    "            print(first_line)\n",
    "        list_meta.append(dict_meta)\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            if line[0] != '>':\n",
    "                sequence += line\n",
    "            else:\n",
    "                dict_meta[\"sequence\"] = sequence\n",
    "                dict_meta = defaultdict(float)\n",
    "                meta_info = p.search(line)\n",
    "                try:\n",
    "                    dict_meta[\"organism\"] = meta_info.group(2)\n",
    "                    dict_meta[\"protein\"] = meta_info.group(1)\n",
    "                    dict_meta[\"class\"] = label\n",
    "                except:\n",
    "                    print(line)\n",
    "                list_meta.append(dict_meta)\n",
    "                data_features.append(sequence)\n",
    "                data_labels.append(label)\n",
    "                sequence = ''\n",
    "        #Last input\n",
    "        list_meta[-1][\"sequence\"] = sequence\n",
    "        data_features.append(sequence)\n",
    "        data_labels.append(label)\n",
    "        sequence = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return data_features, data_labels,list_meta\n",
    "\n",
    "dic_properties = {\n",
    "    'small' : ['A','G','C','S','P','N','C','T','D'],\n",
    "    'tiny' : ['A','G','C','S'],\n",
    "    'polar' : ['K','H','R','D','E','Q','N','S','C','T','Y','W'],\n",
    "    'charged' : ['K','H','R','D','E'],\n",
    "    'positive' : ['K','H','R'],\n",
    "    'negative' :  ['D','E'],\n",
    "    'hidrophobic' : ['F','Y','W','H','I','L','V','A','G','C','M','K','T'],\n",
    "    'aromatic' : ['F','Y','W','H'],\n",
    "    'aliphatic' : ['I','L','V']\n",
    "    \n",
    "}\n",
    "\n",
    "H01={'A':0.62,'C':0.29,'D':-0.90,'E':-0.74,'F':1.19,'G':0.48,'H':-0.40,'I':1.38,'K':-1.50,'L':1.06,'M':0.64,'N':-0.78,'P':0.12,'Q':-0.85,'R':-2.53,'S':-0.18,'T':-0.05,'V':1.08,'W':0.81,'Y':0.26}\n",
    "#H02={'A':-0.5,'C':-1.0,'D':3.0,'E':3.0,'F':-2.5,'G':0.0,'H':-0.5,'I':-1.8,'K':3.0,'L':-1.8,'M':-1.3,'N':0.2,'P':0.0,'Q':0.2,'R':3.0,'S':0.3,'T':-0.4,'V':-1.5,'W':-3.4,'Y':-2.3}\n",
    "H02 = {'G': 0.1116735419503796, 'D': 1.6699090110254438, 'Y': -1.0829736510071695, 'F': -1.1868560156121739, 'K': 1.6699090110254438, 'C': -0.40773828107464183, 'P': 0.1116735419503796, 'R': 1.6699090110254438, 'H': -0.14803236956213112, 'T': -0.096091187259628966, 'V': -0.66744419258715248, 'L': -0.82326773949465892, 'M': -0.56356182798214816, 'Q': 0.2155559065553839, 'W': -1.6543266563346932, 'S': 0.26749708885788603, 'N': 0.2155559065553839, 'A': -0.14803236956213112, 'I': -0.82326773949465892, 'E': 1.6699090110254438}\n",
    "#M0={'A':15.0,'C':47.0,'D':59.0,'E':73.0,'F':91.0,'G':1.0,'H':82.0,'I':57.0,'K':73.0,'L':57.0,'M':75.0,'N':58.0,'P':42.0,'Q':72.0,'R':101.0,'S':31.0,'T':45.0,'V':43.0,'W':130.0,'Y':107.0}\n",
    "M0 = {'G': -2.0046576852358164, 'D': -0.12781917444199323, 'Y': 1.4254264896632398, 'F': 0.9076779349614954, 'K': 0.32521081092203308, 'C': -0.51613059046830145, 'P': -0.67792701381259657, 'R': 1.2312707816500856, 'H': 0.61644437294176424, 'T': -0.58084915980601948, 'V': -0.6455677291437375, 'L': -0.19253774377971125, 'M': 0.3899293802597511, 'Q': 0.29285152625317407, 'W': 2.1696900370469971, 'S': -1.0338791451700458, 'N': -0.16017845911085224, 'A': -1.5516276998717902, 'I': -0.19253774377971125, 'E': 0.32521081092203308}\n",
    "\n",
    "def pseudo_theta(ri,rj):\n",
    "    return 1/3 * ((H01[rj]-H01[ri])**2 + (H02[rj]-H02[ri])**2 + (M0[rj]-M0[ri])**2 )\n",
    "\n",
    "def pseudo_sequence(sequence,tier):\n",
    "    total = 0 \n",
    "    for i in range(1,len(sequence)-tier):\n",
    "        aa_i = sequence[i]\n",
    "        aa_j = sequence[i+1]\n",
    "        total = total + pseudo_theta(aa_i,aa_j)\n",
    "    return total/(len(sequence)-tier)\n",
    "\n",
    "def feat_extract(sequences):\n",
    "    list_dict_feat = []\n",
    "    i = 0\n",
    "    for sequence in sequences:\n",
    "        i+=1\n",
    "        if i%1000 == 0:\n",
    "            print(\"{} sequences processed\".format(i))\n",
    "        protein = ProteinAnalysis(sequence)\n",
    "        sequence_feat = defaultdict(float)\n",
    "        sequence_len = len(sequence)\n",
    "\n",
    "        sequence_feat[\"sequence_length\"] = sequence_len        \n",
    "        sequence_feat[\"aromaticty\"] = protein.aromaticity()\n",
    "        sequence_feat[\"isoeletric_point\"] = protein.isoelectric_point()\n",
    "\n",
    "        if ('X' not in sequence) and ('O' not in sequence) and ('U' not in sequence) and ('B' not in sequence):\n",
    "            sequence_feat[\"pseudo_1\"] = pseudo_sequence(sequence,1)\n",
    "            sequence_feat[\"pseudo_2\"] = pseudo_sequence(sequence,2)\n",
    "            sequence_feat[\"pseudo_3\"] = pseudo_sequence(sequence,3)\n",
    "            sequence_feat[\"pseudo_4\"] = pseudo_sequence(sequence,4)\n",
    "            sequence_feat[\"pseudo_5\"] = pseudo_sequence(sequence,5)\n",
    "            sequence_feat[\"pseudo_6\"] = pseudo_sequence(sequence,6)\n",
    "            sequence_feat[\"pseudo_7\"] = pseudo_sequence(sequence,7)\n",
    "        for letter in sequence:\n",
    "            sequence_feat[\"relative_fre_{}\".format(letter)] += 1/sequence_len #AA composition\n",
    "            for property in dic_properties:\n",
    "                if letter in dic_properties[property]:\n",
    "                    sequence_feat['relative_freq_{}'.format(property)] += 1/sequence_len # grouped AA composition\n",
    "        for letter in sequence[0:50]: # First 50 AA\n",
    "            \n",
    "            sequence_feat[\"relative_fre_start{}\".format(letter)] += 1/50\n",
    "            for property in dic_properties:\n",
    "                if letter in dic_properties[property]:\n",
    "                    sequence_feat['relative_freq_start{}'.format(property)] += 1/50 \n",
    "        for letter in sequence[-51:-1]: #Last 50 AA\n",
    "            \n",
    "            sequence_feat[\"relative_fre_end{}\".format(letter)] += 1/50\n",
    "            for property in dic_properties:\n",
    "                if letter in dic_properties[property]:\n",
    "                    sequence_feat['relative_freq_end{}'.format(property)] += 1/sequence_len \n",
    "        list_dict_feat.append(sequence_feat)\n",
    "    \n",
    "    return list_dict_feat\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "data_sequence, data_labels, meta_info = preprocess_pipeline('cyto.fasta', 'mito.fasta','nucleus.fasta','secreted.fasta')\n",
    "print(len(data_sequence))\n",
    "print(\"Loaded data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_regression():\n",
    "    labels_enc = label_encoder.fit_transform(data_labels)\n",
    "    features_enc = vectorizer.fit_transform(feat_extract(data_sequence))  \n",
    "    lasso = Lasso(alpha=.01)\n",
    "    lasso.fit(features_enc,labels_enc)\n",
    "    print(lasso.coef_)\n",
    "    return lasso\n",
    "lasso = lasso_regression()\n",
    "vectorizer.inverse_transform(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(feat_extract(data_sequence))\n",
    "feature_df= feature_df.fillna(value=0)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(feature_df)\n",
    "df_normalized = pd.DataFrame(np_scaled)\n",
    "#pca_bio = PCA(n_components =70)\n",
    "#features_normalized = pca_bio.fit_transform(df_normalized)\n",
    "features_normalized = pd.concat([feature_df,df_normalized], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_rf(x,y):\n",
    "    model = RandomForestClassifier(class_weight='balanced',n_estimators=15)\n",
    "    model.fit(x, y)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_xgb(x,y):\n",
    "    model = xgboost.XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "    model.fit(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_svm(x,y):\n",
    "    class_weight = {0:0.000001, 1:0.000001, 2:100000000,3:1000000000}\n",
    "    model = SVC(probability=True, class_weight=class_weight)\n",
    "    model.fit(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lr(x,y):\n",
    "    model = LogisticRegression(class_weight='balanced',C=0.1)\n",
    "    model.fit(x, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gnb(x,y):\n",
    "    model = GaussianNB()\n",
    "    model.fit(x,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_knn(x,y):\n",
    "    model = KNeighborsClassifier() # 5 NN by default\n",
    "    model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(x,y):\n",
    "    \n",
    "    labels_enc = label_encoder.fit_transform(y)\n",
    "    features_enc = vectorizer.fit_transform(feat_extract(x))    \n",
    "    #features_enc = vectorizer.fit_transform(x)\n",
    "    #features_enc = x\n",
    "    print(\"Feature Extraction done.\")\n",
    "    clf_rf = train_rf(features_enc,y)\n",
    "    print(\"Random Forest model done.\")\n",
    "    clf_xgb = train_xgb(features_enc,y)\n",
    "    print(\"XGBoost model done.\")\n",
    "    clf_svm = train_svm(features_enc,labels_enc)\n",
    "    print(\"SVM model done.\")\n",
    "    clf_lr = train_lr(features_enc,y)\n",
    "    print(\"Logistic Regression model done.\")\n",
    "    clf_gnb = train_gnb(features_enc,y)\n",
    "    print(\"Gaussian Naive Bayes model done.\")\n",
    "    clf_knn = train_knn(features_enc,y)\n",
    "    print(\"5-Nearest Neighbors model done.\")\n",
    "    model = VotingClassifier([('rf',clf_rf),('xgb',clf_xgb),('lr',clf_lr)],voting='soft')\n",
    "    model.fit(features_enc,y)\n",
    "    print(\"Voting classifier done.\")\n",
    "    return knn\n",
    "\n",
    "def predict(x,model):\n",
    "    \n",
    "    \n",
    "    features = vectorizer.transform(feat_extract(x))\n",
    "    #features = vectorizer.transform(x)\n",
    "    #features = x\n",
    "    predicts = model.predict_proba(features)  \n",
    "    predicts_label = np.argmax(predicts,1)\n",
    "    labels_predicted = label_encoder.inverse_transform(predicts_label)\n",
    "    #label_and_confidence = list(zip(labels_predicted,np.amax(predicts,1)))\n",
    "\n",
    "    return labels_predicted#,np.amax(predicts,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 sequences processed\n",
      "2000 sequences processed\n",
      "3000 sequences processed\n",
      "4000 sequences processed\n",
      "5000 sequences processed\n",
      "6000 sequences processed\n",
      "7000 sequences processed\n",
      "8000 sequences processed\n",
      "9000 sequences processed\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   3.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   2.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   2.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   2.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   2.6s\n",
      "0.570964247021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.5s finished\n"
     ]
    }
   ],
   "source": [
    "def cross_validation_bio(x,y):\n",
    "    labels_enc = label_encoder.fit_transform(y)\n",
    "    features_enc = vectorizer.fit_transform(feat_extract(x))\n",
    "    m1 = RandomForestClassifier(class_weight='balanced',n_estimators=1000,n_estimators=18)\n",
    "    m2 = xgboost.XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "    #m3 = SVC(class_weight='balanced', probability=True)\n",
    "    m4 = LogisticRegression(class_weight='balanced',C=10)\n",
    "    #m5 = GaussianNB()\n",
    "    #m5 = KNeighborsClassifier()\n",
    "    model = VotingClassifier([('rf',m1),('xgb',m2),('lr',m4)],voting='soft',weights=[0.35,0.45,0.2])\n",
    "    rs = ShuffleSplit(n_splits=5, random_state=1)   \n",
    "    cv_bio = cross_val_score(m5,features_enc,labels_enc,cv=rs, verbose=2)\n",
    "    return cv_bio\n",
    "cv_scores = cross_validation_bio(data_sequence,data_labels)\n",
    "print(np.mean(cv_scores))                    \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 sequences processed\n",
      "2000 sequences processed\n",
      "3000 sequences processed\n",
      "4000 sequences processed\n",
      "5000 sequences processed\n",
      "6000 sequences processed\n",
      "7000 sequences processed\n",
      "8000 sequences processed\n",
      "9000 sequences processed\n",
      "RF model created, starting grid search...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] max_features=15 .................................................\n",
      "[CV] .................. max_features=15, score=0.672806, total= 1.1min\n",
      "[CV] max_features=15 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. max_features=15, score=0.672806, total= 1.1min\n",
      "[CV] max_features=15 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. max_features=15, score=0.692308, total= 1.1min\n",
      "[CV] max_features=15 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. max_features=15, score=0.647887, total= 1.1min\n",
      "[CV] max_features=15 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. max_features=15, score=0.664139, total= 1.1min\n",
      "[CV] max_features=18 .................................................\n",
      "[CV] .................. max_features=18, score=0.666306, total= 1.3min\n",
      "[CV] max_features=18 .................................................\n",
      "[CV] .................. max_features=18, score=0.676056, total= 1.3min\n",
      "[CV] max_features=18 .................................................\n",
      "[CV] .................. max_features=18, score=0.702059, total= 1.3min\n",
      "[CV] max_features=18 .................................................\n",
      "[CV] .................. max_features=18, score=0.653304, total= 1.3min\n",
      "[CV] max_features=18 .................................................\n",
      "[CV] .................. max_features=18, score=0.660888, total= 1.3min\n",
      "[CV] max_features=20 .................................................\n",
      "[CV] .................. max_features=20, score=0.672806, total= 1.5min\n",
      "[CV] max_features=20 .................................................\n",
      "[CV] .................. max_features=20, score=0.683640, total= 1.4min\n",
      "[CV] max_features=20 .................................................\n",
      "[CV] .................. max_features=20, score=0.697725, total= 1.4min\n",
      "[CV] max_features=20 .................................................\n",
      "[CV] .................. max_features=20, score=0.654388, total= 1.5min\n",
      "[CV] max_features=20 .................................................\n",
      "[CV] .................. max_features=20, score=0.661972, total= 1.5min\n",
      "[CV] max_features=22 .................................................\n",
      "[CV] .................. max_features=22, score=0.670639, total= 1.6min\n",
      "[CV] max_features=22 .................................................\n",
      "[CV] .................. max_features=22, score=0.671723, total= 1.6min\n",
      "[CV] max_features=22 .................................................\n",
      "[CV] .................. max_features=22, score=0.698808, total= 1.6min\n",
      "[CV] max_features=22 .................................................\n",
      "[CV] .................. max_features=22, score=0.644637, total= 1.6min\n",
      "[CV] max_features=22 .................................................\n",
      "[CV] .................. max_features=22, score=0.668472, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 27.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.594966</td>\n",
       "      <td>0.285174</td>\n",
       "      <td>0.669989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_features': 15}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.672806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.672806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940569</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.059901</td>\n",
       "      <td>0.299849</td>\n",
       "      <td>0.671723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_features': 18}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004196</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.141696</td>\n",
       "      <td>0.289465</td>\n",
       "      <td>0.674106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 20}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.654388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.001935</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>0.015404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.179440</td>\n",
       "      <td>0.293048</td>\n",
       "      <td>0.670856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>{'max_features': 22}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.670639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.671723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.596863</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.017177</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0      64.594966         0.285174         0.669989               1.0   \n",
       "1      78.059901         0.299849         0.671723               1.0   \n",
       "2      87.141696         0.289465         0.674106               1.0   \n",
       "3      95.179440         0.293048         0.670856               1.0   \n",
       "\n",
       "  param_max_features                params  rank_test_score  \\\n",
       "0                 15  {'max_features': 15}                4   \n",
       "1                 18  {'max_features': 18}                2   \n",
       "2                 20  {'max_features': 20}                1   \n",
       "3                 22  {'max_features': 22}                3   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0           0.672806                 1.0           0.672806       ...          \n",
       "1           0.666306                 1.0           0.676056       ...          \n",
       "2           0.672806                 1.0           0.683640       ...          \n",
       "3           0.670639                 1.0           0.671723       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.692308                 1.0           0.647887   \n",
       "1           0.702059                 1.0           0.653304   \n",
       "2           0.697725                 1.0           0.654388   \n",
       "3           0.698808                 1.0           0.644637   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0                 1.0           0.664139                 1.0      0.940569   \n",
       "1                 1.0           0.660888                 1.0      1.004196   \n",
       "2                 1.0           0.661972                 1.0      1.001935   \n",
       "3                 1.0           0.668472                 1.0      0.596863   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.001825        0.014399              0.0  \n",
       "1        0.015898        0.016882              0.0  \n",
       "2        0.006761        0.015404              0.0  \n",
       "3        0.013293        0.017177              0.0  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=20, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grid_search(x,y,model):\n",
    "    \n",
    "    x = vectorizer.fit_transform(feat_extract(x))\n",
    "    if model == 'svm':\n",
    "        parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10]}\n",
    "        model = SVC(class_weight='balanced', probability=True)\n",
    "        print(\"SVM model created, starting grid search...\")\n",
    "    elif model == 'lr':\n",
    "        parameters = {'C':[0.001, 0.1, 1, 10, 100]}\n",
    "        model = LogisticRegression(class_weight='balanced')\n",
    "        print(\"LR model created, starting grid search...\")\n",
    "    elif model == 'rf':\n",
    "        parameters ={'max_features':[15,18,20,22]}\n",
    "        model = RandomForestClassifier(n_estimators=1000)\n",
    "        print(\"RF model created, starting grid search...\")\n",
    "        \n",
    "    rs = ShuffleSplit(n_splits=5, random_state=1)  \n",
    "    grid_search = GridSearchCV(model,parameters,verbose=5,cv=rs)\n",
    "    grid_search.fit(x,y)\n",
    "    print(\"Grid Search finished\")\n",
    "    display(pd.DataFrame(grid_search.cv_results_ ))\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "grid_search(data_sequence,data_labels,'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 sequences processed\n",
      "2000 sequences processed\n",
      "3000 sequences processed\n",
      "4000 sequences processed\n",
      "5000 sequences processed\n",
      "6000 sequences processed\n",
      "Feature Extraction done.\n",
      "Random Forest model done.\n",
      "XGBoost model done.\n",
      "SVM model done.\n",
      "Logistic Regression model done.\n",
      "Gaussian Naive Bayes model done.\n",
      "5-Nearest Neighbors model done.\n",
      "Voting classifier done.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-96da68fb51e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_sequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#train_x, val_x, train_y, val_y = train_test_split(features_normalized,data_labels,test_size=0.3,random_state=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-3c631de37a85>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Voting classifier done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'knn' is not defined"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(data_sequence,data_labels,test_size=0.3,random_state=3)\n",
    "#train_x, val_x, train_y, val_y = train_test_split(features_normalized,data_labels,test_size=0.3,random_state=3)\n",
    "classifier = train(train_x,train_y)\n",
    "\n",
    "pred_y = predict(val_x,classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[549 153 179  25]\n",
      " [ 65 286  10  23]\n",
      " [457  80 423  29]\n",
      " [106 131  21 230]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.466440</td>\n",
       "      <td>0.605960</td>\n",
       "      <td>0.527124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.427705</td>\n",
       "      <td>0.521578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.749186</td>\n",
       "      <td>0.471311</td>\n",
       "      <td>0.578616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1\n",
       "0   0.466440  0.605960  0.527124\n",
       "1   0.440000  0.744792  0.553191\n",
       "2   0.668246  0.427705  0.521578\n",
       "3   0.749186  0.471311  0.578616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(val_y,pred_y)\n",
    "stats =  precision_recall_fscore_support(val_y,pred_y)\n",
    "stats_all =  precision_recall_fscore_support(val_y,pred_y,average='weighted')\n",
    "stats = pd.DataFrame(data=np.transpose(np.array(stats[0:3])),columns=['precision','recall','f1'])\n",
    "stats_all = pd.DataFrame(np.array(stats_all[0:3])).T\n",
    "print(cm)\n",
    "\n",
    "display(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5377665341525117\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(0,len(val_y)):\n",
    "    if val_y[i] == pred_y[i]:\n",
    "        count += 1\n",
    "print(count/len(val_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_blind(file,model):\n",
    "    f = open(file,'r')\n",
    "    preds = open('blind_predictions.txt','w')\n",
    "    sequence = ''\n",
    "    \n",
    "    first_line= f.readline()\n",
    "    first_line = first_line.rstrip('\\n')\n",
    "    preds.write(first_line + ' ')\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        line = line.rstrip('\\n')\n",
    "        if line[0] != '>':\n",
    "            sequence += line\n",
    "        else:\n",
    "            #import pdb;pdb.set_trace()\n",
    "            feature = vectorizer.transform(feat_extract([sequence]))\n",
    "            print(feature)\n",
    "            predict = model.predict_proba(feature)\n",
    "            predict_label = np.argmax(predict,1)\n",
    "            label_predicted = label_encoder.inverse_transform(predict_label)\n",
    "            #preds.write(label_predicted[0] + ' \\t\\t' + str(np.amax(predict,1)[0]) + '\\n' + line + ' ')\n",
    "            preds.write(\"{0} {1:>8} \\n{2} \".format(label_predicted[0],str(np.amax(predict,1)[0]),line))\n",
    "            sequence = ''\n",
    "    feature = vectorizer.transform(feat_extract([sequence]))\n",
    "    predict = model.predict_proba(feature)\n",
    "    predict_label = np.argmax(predict,1)\n",
    "    label_predicted = label_encoder.inverse_transform(predict_label)\n",
    "    #preds.write(label_predicted[0] + ' \\t\\t' + str(np.amax(predict,1)[0]) + '\\n' + line + ' ')\n",
    "    preds.write(\"{0} {1}\".format(label_predicted[0],str(np.amax(predict,1)[0]),line))\n",
    "    sequence = ''\n",
    "    preds.close()\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_blind('blind.fasta',classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = info[info[0].str.contains('(X|O|U|B)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_y = predict(train_x,classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame([H02]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = (df -df.mean())/df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oal =GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
